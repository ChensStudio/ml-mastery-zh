# 机器学习模型选择的温和介绍

> 原文：<https://machinelearningmastery.com/a-gentle-introduction-to-model-selection-for-machine-learning/>

考虑到像 [scikit-learn](https://machinelearningmastery.com/machine-learning-in-python-step-by-step/) 和 [Keras](https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/) 这样易于使用的机器学习库，在给定的预测建模数据集上拟合许多不同的机器学习模型是很简单的。

因此，应用机器学习的挑战就变成了如何在一系列不同的模型中进行选择，以解决你的问题。

天真地，你可能认为模型表现已经足够了，但是你应该考虑其他问题，比如模型需要多长时间来训练或者向项目涉众解释有多容易。如果选择的模型必须在操作中使用数月或数年，他们的担忧会变得更加紧迫。

还有，你到底在选什么:只是用来拟合模型的算法还是整个数据准备和模型拟合流水线？

在这篇文章中，你将发现机器学习模型选择的挑战。

看完这篇文章，你会知道:

*   模型选择是为预测建模问题从众多候选模型中选择一个模型的过程。
*   在执行模型表现之外的模型选择时，可能会有许多相互竞争的问题，例如复杂性、可维护性和可用资源。
*   模型选择技术的两个主要类别是概率度量和重采样方法。

我们开始吧。

![A Gentle Introduction to Model Selection for Machine Learning](img/44ffa8c3e2d7d07607a3041dc141000e.png)

机器学习模型选择简介
图片由[伯纳德·斯拉格提供。新西兰](https://flickr.com/photos/volvob12b/9013738924/)，保留部分权利。

## 概观

本教程分为三个部分；它们是:

1.  什么是型号选择
2.  型号选择的注意事项
3.  模型选择技术

## 什么是型号选择

模型选择是从训练数据集的候选机器学习模型集合中选择一个[最终机器学习模型](https://machinelearningmastery.com/train-final-machine-learning-model/)的过程。

模型选择是一个可以跨不同类型的模型(如逻辑回归、SVM、KNN 等)应用的过程。)和配置有不同模型超参数(例如，SVM 中的不同核)的相同类型的模型。

> 当我们有各种不同复杂度的模型(例如，不同多项式次数的线性或逻辑回归模型，或者 K 值不同的 KNN 分类器)时，我们应该如何选择正确的模型？

—第 22 页，[机器学习:概率视角](https://amzn.to/2AeFDYg)，2012。

例如，我们可能有一个对开发分类或回归预测模型感兴趣的数据集。我们事先不知道哪种模型在这个问题上表现最好，因为它是不可知的。因此，我们在这个问题上拟合和评估了一套不同的模型。

**模型选择**是选择其中一个模型作为解决问题的最终模型的过程。

模型选择不同于**模型评估**。

例如，我们评估或评估候选模型，以便选择最佳模型，这就是模型选择。然而，一旦选择了一个模型，就可以对其进行评估，以便传达它的总体表现；这是模型评估。

> 评估模型表现的过程称为模型评估，而为模型选择适当的灵活性级别的过程称为模型选择。

—第 175 页，[统计学习导论:在 R](https://amzn.to/2LqnsFs) 中的应用，2017。

## 型号选择的注意事项

拟合模型相对简单，尽管选择模型是应用机器学习真正的[挑战。](https://machinelearningmastery.com/applied-machine-learning-is-hard/)

首先，我们需要克服一个“*最佳*”模型的想法。

考虑到数据中的统计噪声、数据样本的不完整性以及每种不同模型类型的局限性，所有模型都有一定的预测误差。因此，完美或最佳模型的概念是没有用的。相反，我们必须寻求一个足够好的模型

**我们在选择最终车型时关心什么？**

项目涉众可能有特定的需求，例如可维护性和有限的模型复杂性。因此，技能较低但更简单、更容易理解的模型可能是首选。

或者，如果模型技能高于所有其他关注点，那么模型在样本外数据上表现良好的能力将是首选，而不考虑所涉及的计算复杂性。

因此，一个足够好的*模型可能会涉及很多东西，并且是针对您的项目的，例如:*

 **   满足项目干系人的要求和约束的模型。
*   考虑到可用的时间和资源，一个足够熟练的模型。
*   与天真的模型相比，这是一个技巧性的模型。
*   一个相对于其他测试模型来说比较熟练的模型。
*   相对于最先进的技术而言，这是一个很有技巧的模型。

接下来，我们必须考虑正在选择什么。

例如，我们没有选择合适的模型，因为所有模型都将被丢弃。这是因为一旦我们选择了一个模型，我们将在所有可用的数据上拟合一个新的最终模型，并开始使用它进行预测。

因此，我们是否在用于拟合训练数据集上的模型的算法中进行选择？

一些算法需要专门的数据准备，以便最好地将问题的结构暴露给学习算法。因此，我们必须更进一步，将**模型选择视为在模型开发管道**中进行选择的过程。

每个管道可以采用相同的原始训练数据集，并输出可以以相同方式评估的模型，但可能需要不同或重叠的计算步骤，例如:

*   数据过滤。
*   数据转换。
*   特征选择。
*   特色工程。
*   还有更多…

你越仔细地观察模型选择的挑战，你就会发现更多的细微差别。

既然我们已经熟悉了模型选择中涉及的一些注意事项，那么让我们回顾一下选择模型的一些常见方法。

## 模型选择技术

模型选择的最佳方法需要“*”足够的*”数据，根据问题的复杂程度，这些数据可能几乎是无限的。

在这种理想的情况下，我们将数据分成[训练、验证和测试集](https://machinelearningmastery.com/difference-test-validation-datasets/)，然后在训练集上拟合候选模型，在验证集上评估和选择它们，并在测试集上报告最终模型的表现。

> 如果我们处于数据丰富的情况下，最好的方法是将数据集随机分成三部分:训练集、验证集和测试集。训练集用于拟合模型；验证集用于估计模型选择的预测误差；测试集用于评估最终选择的模型的泛化误差。

—第 222 页，[统计学习的要素:数据挖掘、推理和预测](https://amzn.to/2N9LDua)，2017。

这在大多数预测建模问题上是不切实际的，因为我们很少有足够的数据，或者甚至能够判断什么是足够的。

> 然而，在许多应用程序中，用于培训和测试的数据供应将是有限的，为了构建良好的模型，我们希望尽可能多地使用可用数据进行培训。然而，如果验证集很小，它将给出预测表现的相对噪声估计。

–第 32 页，[模式识别和机器学习](https://amzn.to/32CTLHi)，2006。

相反，有两类主要的技术来近似模型选择的理想情况；它们是:

*   **概率测度**:通过样本内误差和复杂度选择模型。
*   **重采样方法**:通过估计的样本外误差选择模型。

让我们依次仔细看看每一个。

### 概率测度

[概率度量](https://machinelearningmastery.com/probabilistic-model-selection-measures)包括使用候选模型在训练数据集上的表现和模型的复杂性对其进行分析评分。

众所周知，训练误差是乐观偏差的，因此不是选择模型的良好基础。可以根据训练误差被认为有多乐观来惩罚表现。这通常使用算法特定的方法来实现，通常是线性的，根据模型的复杂性来惩罚分数。

> 历史上已经提出了各种“信息标准”，试图通过增加惩罚项来纠正最大似然偏差，以补偿更复杂模型的过度拟合。

–第 33 页，[模式识别和机器学习](https://amzn.to/32CTLHi)，2006。

具有较少[参数](https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/)的模型不太复杂，因此更受欢迎，因为它可能会更好地概括平均水平。

四种常用的概率模型选择方法包括:

*   阿卡克信息标准(AIC)。
*   贝叶斯信息标准(BIC)。
*   最小描述长度。
*   结构风险最小化。

当使用更简单的线性模型(如线性回归或逻辑回归)时，概率测量是合适的，其中模型复杂性损失的计算(例如在样本偏差中)是已知的且易于处理的。

### 重采样方法

[重采样方法](https://machinelearningmastery.com/statistical-sampling-and-resampling/)寻求在样本外数据上估计模型(或者更准确地说，模型开发过程)的表现。

这是通过将训练数据集分成子训练集和测试集，在子训练集上拟合模型，并在测试集上对其进行评估来实现的。这个过程可以重复多次，并报告每次试验的平均表现。

这是一种对样本外数据的模型表现的[蒙特卡罗估计](https://machinelearningmastery.com/monte-carlo-sampling-for-probability)，尽管每次试验并不是严格独立的，因为根据所选择的重采样方法，相同的数据可能在不同的训练数据集或测试数据集中出现多次。

三种常见的重采样模型选择方法包括:

*   随机训练/测试分割。
*   [交叉验证](https://machinelearningmastery.com/k-fold-cross-validation/) (k-fold，LOOCV 等。).
*   [自举](https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/)。

大多数时间概率测量(在前面部分中描述)不可用，因此使用重采样方法。

到目前为止，最流行的是交叉验证系列方法，包括许多子类型。

> 估计预测误差最简单和最广泛使用的方法可能是交叉验证。

—第 241 页，[统计学习的要素:数据挖掘、推理和预测](https://amzn.to/2N9LDua)，2017。

一个例子是广泛使用的 k 折叠交叉验证，它将训练数据集分成 k 个折叠，每个例子在测试集中只出现一次。

另一种是省略(LOOCV)，其中测试集由单个样本组成，每个样本都有机会成为测试集，需要构建和评估 N(训练集中样本的数量)个模型。

## 进一步阅读

如果您想更深入地了解这个主题，本节将提供更多资源。

### 教程

*   [AIC、BIC 和 MDL 的概率模型选择](https://machinelearningmastery.com/probabilistic-model-selection-measures)
*   [统计采样和重采样的简单介绍](https://machinelearningmastery.com/statistical-sampling-and-resampling/)
*   [概率蒙特卡罗抽样的温和介绍](https://machinelearningmastery.com/monte-carlo-sampling-for-probability)
*   [k 倍交叉验证的温和介绍](https://machinelearningmastery.com/k-fold-cross-validation/)
*   [测试数据集和验证数据集有什么区别？](https://machinelearningmastery.com/difference-test-validation-datasets/)

### 书

*   [应用预测建模](https://amzn.to/2Nb7AJ2)，2013。
*   [统计学习的要素:数据挖掘、推理和预测](https://amzn.to/2N9LDua)，2017。
*   [统计学习导论:在 R](https://amzn.to/2LqnsFs) 中的应用，2017。
*   [模式识别与机器学习](https://amzn.to/32CTLHi)，2006。
*   [机器学习:概率视角](https://amzn.to/2AeFDYg)，2012。

### 文章

*   [车型选择，维基百科](https://en.wikipedia.org/wiki/Model_selection)。

## 摘要

在这篇文章中，你发现了机器学习模型选择的挑战。

具体来说，您了解到:

*   模型选择是为预测建模问题从众多候选模型中选择一个模型的过程。
*   在执行模型表现之外的模型选择时，可能会有许多相互竞争的问题，例如复杂性、可维护性和可用资源。
*   模型选择技术的两个主要类别是概率度量和重采样方法。

你有什么问题吗？
在下面的评论中提问，我会尽力回答。*